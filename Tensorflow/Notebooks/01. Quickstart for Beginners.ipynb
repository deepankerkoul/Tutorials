{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the first notebook in the learning tensorflow series based on the tensorflow documentation. The flow of notebooks/topics is as follows:\n",
    "\n",
    "**1. Quickstart for Beginners** **[We are here]**\n",
    "\n",
    "## Beginner\n",
    "* **ML Basics with Keras**\n",
    "  1. Basic Image Classification\n",
    "  2. Text classification with TF.Hub\n",
    "  3. Text classification with preprocessed text\n",
    "  4. Regression\n",
    "  5. Overfil and underfit\n",
    "  6. Save and load\n",
    "  \n",
    "  \n",
    "* **Load and Preprocess Data**\n",
    "  7. CSV\n",
    "  8. NumPy\n",
    "  9. pandas.DataFrame\n",
    "  10. Images\n",
    "  11. Text\n",
    "  12. Unicode\n",
    "  13. TF.Text\n",
    "  14. TFRecord and tf.Example\n",
    "  \n",
    "  \n",
    "* **Estimator**\n",
    "  15. Premade estimator\n",
    "  16. Linear model\n",
    "  17. Boosted trees\n",
    "  18. Boosted trees model understanding\n",
    "  19. Keras model to Estimator\n",
    "\n",
    "\n",
    "**20. Quickstart for Experts**\n",
    "\n",
    "\n",
    "* **Customization**\n",
    "  21. Tensors and operations\n",
    "  22. Custom layers\n",
    "  23. Automatic differentiation\n",
    "  24. Custom training\n",
    "  25. Custom training: walkthrough\n",
    "  26. Performance with tf.function\n",
    "\n",
    "\n",
    "* **Distributed training**\n",
    "  27. Distributed training with Keras\n",
    "  28. Custom training loops\n",
    "  29. Multi-worker training with Keras\n",
    "  30. Multi-worker training with Estimator\n",
    "  31. Save and load\n",
    "  \n",
    "  \n",
    "* **Images**\n",
    "  32. Convolutional Neural Network\n",
    "  33. Image Classification\n",
    "  34. Transfer Learning with TF.Hub\n",
    "  35. Transfer Learning with pretrained CNN\n",
    "  36. Image Segmentation\n",
    "  37. Object Detection with TFHub\n",
    "  \n",
    "  \n",
    "* **Text**\n",
    "  38. Word Embeddings\n",
    "  39. Text Classification with an RNN\n",
    "  40. Text generation with an RNN\n",
    "  41. Neural Machine Translation with Attention\n",
    "  42. Image Captioning\n",
    "  43. Transformer Model for Language Understanding\n",
    "  \n",
    "  \n",
    "* **Structured Data**\n",
    "  44. Classify Structured Data with Feature COlumns\n",
    "  45. Classification on Imbalanced Data\n",
    "  46. Time Series Forecasting\n",
    "  \n",
    "  \n",
    "* **Generative**\n",
    "  47. Neural Style Transfer\n",
    "  48. DeepDream\n",
    "  49. DCGAN\n",
    "  50. Pix2Pix\n",
    "  51. CycleGAN\n",
    "  52. Adversarial FGSM\n",
    "  53. Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(train_examples, train_labels), (test_examples, test_labels) = mnist.load_data()\n",
    "train_examples = train_examples / 255.0\n",
    "test_examples = test_examples / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layers in Tensorflow\n",
    "Most of the code that we write now (in Tensorflow 2.0) will make use of the Keras API. The rest of the methods are still available for customisation, but for rapid prototyping, Keras contains most of the modules that we need to get started.\n",
    "\n",
    "Here we have used a **[Sequential](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential)** model.\n",
    "The **Sequential** class is directly part of the tf.keras and represents a linear stack of layers. In tf1, it was present under tf.keras.models.sequential\n",
    "\n",
    "The Sequential class takes in a list of layers as arguments. The layers inherit from tf.keras.layers. Here we have used the following types of layers:\n",
    "  * **Flatten**: Flatten layer Flattens the input but does not affect the batch size. If inputs are shaped `(batch,)` without a channel dimension, then flattening adds an extra channel dimension and output shapes are `(batch, 1)`.\n",
    "  \n",
    "  \n",
    "  * **Dense**: Dense layer represents a regular densely-connected NN layer.\n",
    "  \n",
    "  `Dense` implements the operation: `output = activation(dot(input, kernel) + bias)` where `activation` is the element-wise activation function passed as the `activation` argument, `kernel` is a weights matrix created by the layer, and `bias` is a bias vector created by the layer (only applicable if `use_bias` is `True`).\n",
    "  \n",
    "  \n",
    "  * **Dropout**: Dropout layer applies Dropout to the input. Dropout consists in randomly setting a fraction rate of input units to 0 at each update during training time, which helps prevent overfitting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here pass a list of layers that for a part of our neural net\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Configures the model for training\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/25\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 0.2932 - accuracy: 0.9145\n",
      "Epoch 2/25\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.1404 - accuracy: 0.9579\n",
      "Epoch 3/25\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.1063 - accuracy: 0.9683\n",
      "Epoch 4/25\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.0873 - accuracy: 0.9733\n",
      "Epoch 5/25\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.0740 - accuracy: 0.9766\n",
      "Epoch 6/25\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.0635 - accuracy: 0.9797\n",
      "Epoch 7/25\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.0581 - accuracy: 0.9815\n",
      "Epoch 8/25\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.0532 - accuracy: 0.9827\n",
      "Epoch 9/25\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.0473 - accuracy: 0.9842\n",
      "Epoch 10/25\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.0447 - accuracy: 0.9850\n",
      "Epoch 11/25\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.0411 - accuracy: 0.9861\n",
      "Epoch 12/25\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.0381 - accuracy: 0.9873\n",
      "Epoch 13/25\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.0347 - accuracy: 0.9882\n",
      "Epoch 14/25\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.0351 - accuracy: 0.9880\n",
      "Epoch 15/25\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.0318 - accuracy: 0.9891\n",
      "Epoch 16/25\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.0300 - accuracy: 0.9896\n",
      "Epoch 17/25\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.0300 - accuracy: 0.9901\n",
      "Epoch 18/25\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.0277 - accuracy: 0.9905\n",
      "Epoch 19/25\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.0270 - accuracy: 0.9906\n",
      "Epoch 20/25\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.0250 - accuracy: 0.9911\n",
      "Epoch 21/25\n",
      "60000/60000 [==============================] - 2s 42us/sample - loss: 0.0249 - accuracy: 0.9918\n",
      "Epoch 22/25\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.0251 - accuracy: 0.9918\n",
      "Epoch 23/25\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.0223 - accuracy: 0.9929\n",
      "Epoch 24/25\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.0236 - accuracy: 0.9919\n",
      "Epoch 25/25\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.0232 - accuracy: 0.9920\n",
      "10000/1 - 0s - loss: 0.0449 - accuracy: 0.9810\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08967536150476042, 0.981]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_examples, train_labels, epochs=25)\n",
    "\n",
    "# model.evaluate Returns the loss value & metrics values for the model in test mode. Computation is done in batches.\n",
    "model.evaluate(test_examples, test_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/1 - 0s - loss: 0.0449 - accuracy: 0.9810\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08967536150476042, 0.981]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_examples, test_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTutes",
   "language": "python",
   "name": "pytutes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
